用户问这个项目的文本向量化是怎么处理的。我需要查看项目结构来理解文本向量化的实现。从项目概述中可以看到这是一个基于 RAG 和知识图谱的项目，使用 LangGraph v1 + Vue.js + FastAPI + LightRAG 架构。

让我查看一下相关文件，特别是：
1. LightRAG 相关的代码
2. 向量化相关的配置
3. API 接口中的向量化处理

首先让我搜索一下 embedding 或 vector 相关的代码。
我来帮你查看这个项目的文本向量化处理方式。让我先搜索相关代码。
从搜索结果可以看到项目中有很多关于 embedding 和 vector 的处理。让我继续查看更具体的文件来了解文本向量化的处理流程。我需要查看：

1. `src/models` 目录中 embedding 模型的选择逻辑
2. `src/knowledge` 目录中向量化的具体实现
3. 可能还有一些 LightRAG 相关的配置

让我先看看 models 目录和 knowledge 目录的结构。
没有找到专门的 embedding 文件。让我看看 models 目录下的文件结构，以及查看 __init__.py 中导出的内容，特别是 select_embedding_model 相关的。
很好，找到了 embedding 相关的文件。让我查看 embed.py 文件来了解向量化的具体实现。
很好，现在我了解了 embedding 模型的实现。让我再查看一下配置文件，了解支持的 embedding 模型有哪些，以及在知识库上传时如何使用这些模型。
让我查看 app.py 配置文件来了解 embedding 模型的完整配置。
-
让我查看默认的 embedding 模型配置。
-
让我看看 static 目录下的文件。
-
找到了，让我查看 static/models.py 文件。
-
现在我对项目的文本向量化处理有了比较清晰的了解。让我再查看一下在知识库上传时如何使用向量化，特别是向量数据库的使用。
-
让我查看 milvus.py 来了解向量数据库的处理。
-
现在我对项目的文本向量化处理有了比较全面的了解。让我整理一下这些信息，为用户提供一个清晰的说明。

主要包含：
1. 向量模型的选择和配置
2. 向量化的流程
3. 向量数据库的使用

让我继续查看一些关键代码来补充信息。
-
现在让我查看一下在 Milvus 中如何进行向量化处理。
-
很好，现在我对项目的文本向量化处理有了清晰的理解。让我查看一下 embedding_function 是如何被创建的。
-
让我查看一下 _get_async_embedding_function 方法的实现。
-
让我查看 _get_async_embedding 方法的实现。
-
让我查看 _get_async_embedding 的实现。
-
现在我已经有足够的信息来回答用户的问题了。让我整理一下项目的文本向量化处理流程。
根据我对项目代码的分析，Yuxi-Know 项目的文本向量化处理流程如下：

## 一、向量模型架构

项目采用模块化的向量化架构，核心在 `src/models/embed.py` 中实现：

### 1. 基础抽象类 `BaseEmbeddingModel`

```160:267:src/models/embed.py
class BaseEmbeddingModel(ABC):
    def encode(self, message: list[str] | str) -> list[list[float]]:
        """同步编码"""
        raise NotImplementedError("Subclasses must implement this method")

    async def aencode(self, message: list[str] | str) -> list[list[float]]:
        """异步编码"""
        raise NotImplementedError("Subclasses must implement this method")

    async def abatch_encode(self, messages: list[str], batch_size: int = 40):
        """异步批量编码，支持进度跟踪"""
```

### 2. 两种实现方式

- **`OllamaEmbedding`**: 用于本地 Ollama 模型
- **`OtherEmbedding`**: 用于云端 API（如 SiliconFlow、OpenAI 等）

### 3. 模型选择机制

```250:266:src/models/embed.py
def select_embedding_model(model_id):
    provider, model_name = model_id.split("/", 1) if model_id else ("", "")
    support_embed_models = config.embed_model_names.keys()
    
    embed_config = config.embed_model_names[model_id].model_dump()
    
    if provider == "ollama":
        model = OllamaEmbedding(**embed_config)
    else:
        model = OtherEmbedding(**embed_config)
    
    return model
```

## 二、支持的向量模型

在 `src/config/static/models.py` 中预定义了多种向量模型：

```160:210:src/config/static/models.py
DEFAULT_EMBED_MODELS: dict[str, EmbedModelInfo] = {
    "siliconflow/BAAI/bge-m3": EmbedModelInfo(
        model_id="siliconflow/BAAI/bge-m3",
        name="BAAI/bge-m3",
        dimension=1024,
        base_url="https://api.siliconflow.cn/v1/embeddings",
        api_key="SILICONFLOW_API_KEY",
    ),
    "vllm/Qwen/Qwen3-Embedding-0.6B": EmbedModelInfo(
        model_id="vllm/Qwen/Qwen3-Embedding-0.6B",
        name="Qwen3-Embedding-0.6B",
        dimension=1024,
        base_url="http://localhost:8000/v1/embeddings",
        api_key="no_api_key",
    ),
    "ollama/nomic-embed-text": EmbedModelInfo(
        model_id="ollama/nomic-embed-text",
        name="nomic-embed-text",
        dimension=768,
        base_url="http://localhost:11434/api/embed",
        api_key="no_api_key",
    ),
    # ... 更多模型
}
```

默认使用 `siliconflow/BAAI/bge-m3` 模型（1024 维）。

## 三、向量化处理流程

### 1. 文档上传与解析

```227:284:src/knowledge/implementations/milvus.py
async def index_file(self, db_id: str, file_id: str, operator_id: str | None = None):
    # 1. 验证文件状态（必须已解析为 Markdown）
    if current_status not in allowed_statuses:
        raise ValueError(f"Cannot index file with status '{current_status}'")
    
    # 2. 读取 Markdown 内容
    markdown_content = await self._read_markdown_from_minio(file_meta["markdown_file"])
    
    # 3. 文本分块
    chunks = self._split_text_into_chunks(markdown_content, file_id, filename, params)
```

### 2. 文本分块

在 `src/knowledge/utils/kb_utils.py` 中使用 MarkdownTextSplitter：

```100:148:src/knowledge/utils/kb_utils.py
# 使用 MarkdownTextSplitter 进行智能分割
text_splitter = MarkdownTextSplitter(
    chunk_size=chunk_size,        # 默认 1000
    chunk_overlap=chunk_overlap,  # 默认 200
)

# 支持自定义分隔符（如 Q&A 格式）
if separator:
    pre_chunks = text.split(separator)
    text_chunks = []
    for pre_chunk in pre_chunks:
        if pre_chunk.strip():
            text_chunks.extend(text_splitter.split_text(pre_chunk))
```

### 3. 批量向量化

```307:320:src/knowledge/implementations/milvus.py
if chunks:
    texts = [chunk["content"] for chunk in chunks]
    embeddings = await embedding_function(texts)  # 批量编码，默认 batch_size=40
    
    entities = [
        [chunk["id"] for chunk in chunks],
        [chunk["content"] for chunk in chunks],
        [chunk["source"] for chunk in chunks],
        [chunk["chunk_id"] for chunk in chunks],
        [chunk["file_id"] for chunk in chunks],
        [chunk["chunk_index"] for chunk in chunks],
        embeddings,  # 向量数据
    ]
```

### 4. 向量函数创建

```175:199:src/knowledge/implementations/milvus.py
def _get_async_embedding(self, embed_info: dict):
    """获取 embedding 函数"""
    if embed_info and "model_id" in embed_info:
        from src.models.embed import select_embedding_model
        return select_embedding_model(embed_info["model_id"])

def _get_async_embedding_function(self, embed_info: dict):
    """获取 embedding 函数（批量编码）"""
    embedding_model = self._get_async_embedding(embed_info)
    return partial(embedding_model.abatch_encode, batch_size=40)
```

## 四、向量存储

项目使用 **Milvus** 作为向量数据库：

### 1. Collection Schema 定义

```136:154:src/knowledge/implementations/milvus.py
def _create_new_collection(self, collection_name: str, embed_info: Any, db_id: str):
    embedding_dim = embed_info.get("dimension", 1024)
    
    fields = [
        FieldSchema(name="id", dtype=DataType.VARCHAR, max_length=100, is_primary=True),
        FieldSchema(name="content", dtype=DataType.VARCHAR, max_length=65535),
        FieldSchema(name="source", dtype=DataType.VARCHAR, max_length=500),
        FieldSchema(name="chunk_id", dtype=DataType.VARCHAR, max_length=100),
        FieldSchema(name="file_id", dtype=DataType.VARCHAR, max_length=100),
        FieldSchema(name="chunk_index", dtype=DataType.INT64),
        FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=embedding_dim),
    ]
```

### 2. 向量索引插入

```324:328:src/knowledge/implementations/milvus.py
def _insert_records():
    collection.insert(entities)

await asyncio.to_thread(_insert_records)
```

## 五、总结

项目的文本向量化处理具有以下特点：

1. **模块化设计**: 通过抽象类和工厂模式支持多种向量模型
2. **异步批处理**: 使用 `abatch_encode` 进行高效批量编码（默认 batch_size=40）
3. **智能分块**: 使用 MarkdownTextSplitter 按语义分块，支持自定义分隔符
4. **向量数据库**: 使用 Milvus 存储向量，支持高效的相似度搜索
5. **模型切换**: 支持在知识库配置时指定不同的向量模型
6. **进度跟踪**: 批量编码时提供进度状态监控